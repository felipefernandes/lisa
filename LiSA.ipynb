{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaCtzDSsV6dnl4AjAuSQ2W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipefernandes/lisa/blob/main/LiSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "wSN_aaruIpsk"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -q -U pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata, drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import random"
      ],
      "metadata": {
        "id": "WJ8xaTlGJFfo"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ConfiguraÃ§Ã£o do GenerativeAI\n",
        "GOOGLE_API_KEY = userdata.get('GEMINIKEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "jRlmthAkKgYN"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listando modelos disponÃ­veis\n",
        "for m in genai.list_models():\n",
        "  if 'embedContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "kRHd9XA4KWOu",
        "outputId": "22f46eaa-6d39-4b73-d7df-edc6b5bd7c8c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-001\n",
            "models/text-embedding-004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CriaÃ§Ã£o de DicionÃ¡rios\n",
        "\n",
        "estruturas = [\n",
        "    {\"nome\": \"Impromptu Networking\", \"duracao\": \"5-20 min\", \"proposito\": \"Compartilhe rapidamente os desafios e as expectativas, crie novas conexÃµes\", \"label\": \"Disseminar\"},\n",
        "    {\"nome\": \"9 Whys\", \"duracao\": \"5-20 min\", \"proposito\": \"Torne claro o propÃ³sito do trabalho juntos\", \"label\": \"Analisar\"},\n",
        "    {\"nome\": \"What, So What, Now What\", \"duracao\": \"15-45 min\", \"proposito\": \"Analisar juntos o progresso atÃ© entÃ£o e decidir quais ajustes sÃ£o necessÃ¡rios\", \"label\": \"Analisar\"},\n",
        "    {\"nome\": \"TRIZ\", \"duracao\": \"30-45 min\", \"proposito\": \"Pare atividades e comportamentos contraproducentes para abrir espaÃ§o para a inovaÃ§Ã£o\", \"label\": \"Revelar\"},\n",
        "    {\"nome\": \"Appreciative Interviews\", \"duracao\": \"30-60 min\", \"proposito\": \"Descobrindo e aproveitando as causas-raiz do sucesso\", \"label\": \"Revelar, Disseminar\"},\n",
        "    {\"nome\": \"1-2-4-All\", \"duracao\": \"10-12 min\", \"proposito\": \"Engage todos simultaneamente na geraÃ§Ã£o de perguntas, ideias e sugestÃµes.\", \"label\": \"Revelar\"},\n",
        "    {\"nome\": \"User Experience Fishbowl\", \"duracao\": \"25-70 min\", \"proposito\": \"Compartilhe com uma comunidade maior a capacidade obtida a partir da experiÃªncia\", \"label\": \"Disseminar\"},\n",
        "    {\"nome\": \"15% Solutions\", \"duracao\": \"15-20 min\", \"proposito\": \"Descubra e concentre-se no que cada pessoa tem a liberdade e os recursos para fazer agora\", \"label\": \"Revelar\"},\n",
        "    {\"nome\": \"25-to-10 Crowdsourcing\", \"duracao\": \"20-30 min\", \"proposito\": \"Gerar e analisar rapidamente as ideias factÃ­veis mais poderosas de um grupo\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Troika Consulting\", \"duracao\": \"15-30 min\", \"proposito\": \"Obtenha ajuda prÃ¡tica e criativa dos colegas imediatamente\", \"label\": \"Ajuda, Revelar\"},\n",
        "    { \"nome\": \"Conversation CafÃ©\", \"duracao\": \"35-60 min\", \"proposito\": \"Engage todos na compreensÃ£o de grandes desafios\", \"label\": \"Disseminar\"},\n",
        "    { \"nome\": \"Min Specs\", \"duracao\": \"20-50 min\", \"proposito\": \"Especifique apenas os absolutos â€œDevemosâ€ e â€œNÃ£o Devemosâ€ para alcanÃ§ar um propÃ³sito\", \"label\": \"EstratÃ©gia\"},\n",
        "    { \"nome\": \"Wise Crowds\", \"duracao\": \"10-60 min. per person\", \"proposito\": \"Acesse a sabedoria do grupo inteiro em ciclos rÃ¡pidos\", \"label\": \"Ajuda, Revelar\"},\n",
        "    { \"nome\": \"Wicked Questions\", \"duracao\": \"20 min\", \"proposito\": \"Articule os desafios paradoxais que um grupo deve enfrentar para ter sucesso\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Drawing Together\", \"duracao\": \"30-40 min\", \"proposito\": \"Revele ideias e caminhos para avanÃ§ar atravÃ©s da expressÃ£o nÃ£o-verbal\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Improv Prototyping\", \"duracao\": \"15-20 min. per round\", \"proposito\": \"Desenvolva soluÃ§Ãµes eficazes para desafios crÃ´nicos, enquanto se diverte seriamente\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Agreement-Certainty Matrix\", \"duracao\": \"30-45 min\", \"proposito\": \"Classifique os desafios nos domÃ­nios simples, complicado, complexo e caÃ³tico\", \"label\": \"AnÃ¡lise\"},\n",
        "    { \"nome\": \"Shift & Share\", \"duracao\": \"35-90 min\", \"proposito\": \"Dissemine boas ideias e faÃ§a conexÃµes informais com inovadores\", \"label\": \"Disseminar\"},\n",
        "    { \"nome\": \"Heard, Seen, Respected\", \"duracao\": \"25 min\", \"proposito\": \"Pratique a escuta profunda e empatia com colegas\", \"label\": \"Ajuda\"},\n",
        "    { \"nome\": \"Social Network Webbing\", \"duracao\": \"45-60 min\", \"proposito\": \"Mapeie conexÃµes informais e decida como fortalecer a rede para alcanÃ§ar um propÃ³sito\", \"label\": \"Ajuda, Disseminar\"},\n",
        "    { \"nome\": \"Design Storyboards\", \"duracao\": \"25-70 min\", \"proposito\": \"Defina os elementos passo-a-passo para conduzir reuniÃµes a finais produtivos\", \"label\": \"Planejar\"},\n",
        "    { \"nome\": \"Open Space\", \"duracao\": \"90 min. to 3 days\", \"proposito\": \"Libere a aÃ§Ã£o e lideranÃ§a inerentes a grupos de qualquer tamanho\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Discovery & Action Dialogue\", \"duracao\": \"25-70 min\", \"proposito\": \"Descubra, invente e desencadeie soluÃ§Ãµes locais para problemas crÃ´nicos\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Integrated Autonomy\", \"duracao\": \"60-80 min\", \"proposito\": \"Mude de soluÃ§Ãµes 'ou-um-ou-outro' para robustas soluÃ§Ãµes 'ambos-e'\", \"label\": \"EstratÃ©gia\"},\n",
        "    { \"nome\": \"Generative Relationships\", \"duracao\": \"25 min\", \"proposito\": \"Revele padrÃµes de relacionamento que criam surpreendente valor ou disfunÃ§Ãµes\", \"label\": \"AnÃ¡lise\"},\n",
        "    { \"nome\": \"Critical Uncertainties\", \"duracao\": \"60-100 min\", \"proposito\": \"Desenvolva estratÃ©gias para operar em uma variedade de futuros plausÃ­veis porÃ©m imprevisÃ­veis\", \"label\": \"EstratÃ©gia\"},\n",
        "    { \"nome\": \"Purpose-to-Practice\", \"duracao\": \"25-120 min\", \"proposito\": \"Desenhe os cinco elementos essenciais para uma iniciativa resiliente e duradoura\", \"label\": \"Planejar\"},\n",
        "    { \"nome\": \"Ecocycle Planning\", \"duracao\": \"60-95 min\", \"proposito\": \"Analise o portfÃ³lio completo de atividades e relacionamentos para identificar obstÃ¡culos e oportunidades para o progresso\", \"label\": \"AnÃ¡lise, EstratÃ©gia\"},\n",
        "    { \"nome\": \"Panarchy\", \"duracao\": \"1-2 hr\", \"proposito\": \"Entenda como sistemas interconectados interagem, evoluem, disseminam inovaÃ§Ã£o e transformam\", \"label\": \"EstratÃ©gia\"},\n",
        "    { \"nome\": \"What I Need From You\", \"duracao\": \"45-70 min\", \"proposito\": \"FaÃ§a emergir as necessidades essenciais entre Ã¡reas e aceite ou rejeite pedidos de suporte\", \"label\": \"Ajuda\"},\n",
        "    { \"nome\": \"Celebrity Interview\", \"duracao\": \"25-60 min\", \"proposito\": \"Reconectar a experiÃªncia de lÃ­deres e especialistas com pessoas mais prÃ³ximas do desafio em mÃ£os\", \"label\": \"Disseminar\"},\n",
        "    { \"nome\": \"Helping Heuristics\", \"duracao\": \"15 min\", \"proposito\": \"Pratique mÃ©todos progressivos para ajudar os outros, receber ajuda e pedir ajuda\", \"label\": \"Ajuda\"},\n",
        "    { \"nome\": \"Simple Ethnography\", \"duracao\": \"1-6 hr\", \"proposito\": \"Observe e registre os comportamentos reais dos usuÃ¡rios em campo\", \"label\": \"AnÃ¡lise, Revelar\"}\n",
        "]\n",
        "\n",
        "solucoes = [\n",
        "    {\"solucao\": \"Revelar, gerar aprimorar idÃ©ias ou soluÃ§Ãµes\"},\n",
        "    {\"solucao\": \"Compartilhar ou disseminar idÃ©ias, conhecimentos ou experiÃªncias\"},\n",
        "    {\"solucao\": \"Analisar, diagnosticar ou processar\"},\n",
        "    {\"solucao\": \"Pedir ou oferecer ajuda\"},\n",
        "    {\"solucao\": \"Elaborar estratÃ©gias\"},\n",
        "    {\"solucao\": \"Planejar\"}\n",
        "]"
      ],
      "metadata": {
        "id": "LhOuJwEfLNgv"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrames\n",
        "\n",
        "* Pense em um DataFrame como uma tabela organizada, com linhas e colunas.\n",
        "* Cada linha representa um roteiro de retrospectiva e cada coluna contÃ©m informaÃ§Ãµes especÃ­ficas sobre esse roteiro, como nome, descriÃ§Ã£o, atividades, etc.\n",
        "* Essa organizaÃ§Ã£o facilita o armazenamento e a busca de informaÃ§Ãµes."
      ],
      "metadata": {
        "id": "kune8xgMRCk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_estruturas = pd.DataFrame(estruturas)\n",
        "df_estruturas.columns = ['nome', 'duracao', 'proposito', 'label']\n",
        "\n",
        "df_solucoes = pd.DataFrame(solucoes)\n",
        "df_solucoes.columns = ['solucao']"
      ],
      "metadata": {
        "id": "a6NXpp_WQTS_"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings\n",
        "\n",
        "* Embeddings sÃ£o como **representaÃ§Ãµes matemÃ¡ticas de textos**, transformando palavras e frases em sequÃªncias de nÃºmeros.\n",
        "* Essa representaÃ§Ã£o numÃ©rica captura o **significado semÃ¢ntico** do texto.\n",
        "* Palavras com significados semelhantes terÃ£o embeddings parecidos, permitindo comparar a similaridade entre textos de forma eficiente.\n",
        "\n",
        "### Juntos, DataFrames e Embeddings permitem:\n",
        "1. **Armazenar os roteiros de forma estruturada** dentro do DataFrame.\n",
        "2. **Converter o contexto fornecido pelo usuÃ¡rio e as descriÃ§Ãµes dos roteiros em embeddings.**\n",
        "3. **Comparar os embeddings usando cÃ¡lculos matemÃ¡ticos**, encontrando os roteiros mais relevantes para o contexto descrito.\n",
        "\n",
        "##### **Em resumo:** DataFrames organizam os dados, enquanto embeddings traduzem os textos em uma linguagem que o computador entende, permitindo encontrar o roteiro perfeito para sua necessidade!"
      ],
      "metadata": {
        "id": "TYgikh5DRLx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando o modelo\n",
        "model = \"models/embedding-001\""
      ],
      "metadata": {
        "id": "5HJkgKzsSOex"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o para adicionar colunas de Embeds no DF Estruturas, conteudo principal titulo e descricao\n",
        "def addEmbeddings(nome, proposito):\n",
        "  return genai.embed_content(model=model, content=proposito, title=nome, task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "\n",
        "# Adicionando Embeddings no DataFrame\n",
        "df_estruturas[\"Embeddings\"] = df_estruturas.apply(lambda row: addEmbeddings(row[\"nome\"], row[\"proposito\"]), axis=1)"
      ],
      "metadata": {
        "id": "KSpVTvukSbre"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o para adicionar uma coluna de Embeddings para Label\n",
        "def addLabelEmbeddings(label):\n",
        "  return genai.embed_content(model=model, content=label, task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "\n",
        "# Adicionando nova coluna de Embeddings para Label\n",
        "df_estruturas[\"LabelEmbeddings\"] = df_estruturas.apply(lambda row: addLabelEmbeddings(row[\"label\"]), axis=1)"
      ],
      "metadata": {
        "id": "_m0yv8OUQimJ"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o para adicionar colunas embeddings no DF de Solucoes\n",
        "def addSolucaoEmbeddings(solucao):\n",
        "  return genai.embed_content(model=model, content=solucao, task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "\n",
        "df_solucoes[\"Embeddings\"] = df_solucoes.apply(lambda row: addSolucaoEmbeddings(row[\"solucao\"]), axis=1)"
      ],
      "metadata": {
        "id": "JBduiZnOR8CA"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Produtos Escalares & Embeddings\n",
        "\n",
        "A funÃ§Ã£o `buscar_solucao_consulta` utiliza uma tÃ©cnica poderosa para encontrar a soluÃ§Ã£o mais adequada para sua consulta: o produto escalar entre embeddings.\n",
        "### Mas como isso funciona?\n",
        "1. **Embeddings**: Cada texto, tanto a sua consulta quanto as soluÃ§Ãµes prÃ©-definidas, Ã© convertido em um embedding, uma representaÃ§Ã£o matemÃ¡tica que captura seu significado. Imagine que cada palavra se transforma em um ponto em um espaÃ§o multidimensional, e frases com significados semelhantes ficam prÃ³ximas nesse espaÃ§o.\n",
        "2. **Produto Escalar**: O produto escalar Ã© uma operaÃ§Ã£o matemÃ¡tica que mede a similaridade entre dois vetores (no nosso caso, os embeddings). Ele leva em consideraÃ§Ã£o a **direÃ§Ã£o** e a **magnitude** dos vetores.\n",
        "  * Um produto escalar alto indica vetores apontando na mesma direÃ§Ã£o, significando alta similaridade entre os textos.\n",
        "  * Um produto escalar baixo indica vetores apontando em direÃ§Ãµes diferentes, significando baixa similaridade.\n",
        "3. **Encontrando a Melhor SoluÃ§Ã£o**: A funÃ§Ã£o calcula o produto escalar entre o embedding da sua consulta e os embeddings de cada soluÃ§Ã£o na base de dados. O Ã­ndice da soluÃ§Ã£o com o **maior produto escalar** indica a soluÃ§Ã£o mais similar Ã  sua consulta, sendo a mais adequada para o contexto descrito.\n",
        "\n",
        "**Em resumo:** o produto escalar atua como um \"termÃ´metro\" de similaridade, permitindo encontrar a soluÃ§Ã£o mais prÃ³xima Ã  sua necessidade, com base no significado semÃ¢ntico dos textos!\n",
        "\n",
        "#### Analogia:\n",
        "Imagine que as palavras sÃ£o como cidades em um mapa. Cidades prÃ³ximas tÃªm mais similaridade. O produto escalar seria como medir a distÃ¢ncia entre a sua \"cidade-consulta\" e as \"cidades-soluÃ§Ãµes\". A cidade-soluÃ§Ã£o mais prÃ³xima (menor distÃ¢ncia, maior produto escalar) Ã© a mais relevante para sua consulta."
      ],
      "metadata": {
        "id": "080qCFNDSYS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o para verificar consulta tem relaÃ§Ã£o com alguma dos itens do DF soluÃ§Ã£o\n",
        "def buscar_solucao_consulta(consulta, base, model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model, content=consulta, task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "  produtos_escalares = np.dot(np.stack(base['Embeddings']), embedding_da_consulta)\n",
        "  indice = np.argmax(produtos_escalares)\n",
        "  return base.iloc[indice]['solucao']"
      ],
      "metadata": {
        "id": "W_WPt6SdUG00"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Limite de Relevancia\n",
        "\n",
        "* O `limite_relevancia` atua como um filtro, determinando quais resultados sÃ£o considerados \"relevantes\" com base no produto escalar entre o embedding da consulta e os embeddings da sua base de dados (`df_estruturas`).\n",
        "* Um produto escalar prÃ³ximo de 1 indica alta similaridade entre os vetores, enquanto um valor prÃ³ximo de 0 indica baixa similaridade.\n",
        "\n",
        "## Ajustando o Limite de Relevancia:\n",
        "* **Aumentar o limite (mais perto de 1)**:\n",
        "  * Somente resultados **muito similares** Ã  consulta serÃ£o considerados relevantes.\n",
        "  * Ãštil se vocÃª deseja resultados **precisos** e tem certeza de que a consulta corresponde bem aos dados na sua base.\n",
        "  * Risco: Pode resultar em **nenhum resultado** se a consulta for muito especÃ­fica ou nÃ£o houver correspondÃªncia exata na base.\n",
        "* **Diminuir o limite (mais perto de 0)**:\n",
        "  * Resultados **menos similares** Ã  consulta tambÃ©m serÃ£o considerados relevantes.\n",
        "  * Ãštil para **explorar** a base de dados ou quando a consulta Ã© mais vaga.\n",
        "  * Risco: Pode retornar **resultados irrelevantes** ou que nÃ£o correspondem exatamente Ã  intenÃ§Ã£o da consulta."
      ],
      "metadata": {
        "id": "GhVO05FrPZ3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o para gerar e buscar e consultar\n",
        "def gerar_e_buscar_consulta(consulta, base, model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model, content=consulta, task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "\n",
        "  produtos_escalares = np.dot(np.stack(df_estruturas['LabelEmbeddings']), embedding_da_consulta)\n",
        "\n",
        "  limite_relevancia = 0.6 # Definindo o limite da relevancia\n",
        "  indices_relevantes = np.where(produtos_escalares >= limite_relevancia)[0]\n",
        "\n",
        "  resultados_relevantes = []\n",
        "  for indice in indices_relevantes:\n",
        "    resultados_relevantes.append(df_estruturas.iloc[indice]['nome'])\n",
        "\n",
        "  top3_resultados_relevantes = []\n",
        "  top3 = 0\n",
        "  if resultados_relevantes:\n",
        "    while top3 < 3 and top3 < len(resultados_relevantes):  # Verifica se hÃ¡ elementos suficientes\n",
        "      # Exibe a primeira posicao de resultados_relevante\n",
        "      top3_resultados_relevantes.append(resultados_relevantes[top3])\n",
        "      top3 += 1\n",
        "    return top3_resultados_relevantes # Exibe uma lista de resultados relevantes\n",
        "  else:\n",
        "    indice = np.argmax(produtos_escalares)\n",
        "    return df_estruturas.iloc[indice]['nome'] # garante que ao menos 1 resultado seja exibido"
      ],
      "metadata": {
        "id": "Clyg4_pBU4jX"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Busca e retorna solucoes e ELs recomendadas de acordo com um Prompt\n",
        "def busca (prompt):\n",
        "  solucao_relacionada = buscar_solucao_consulta(prompt, df_solucoes, model)\n",
        "  estruturas_recomendadas = gerar_e_buscar_consulta(prompt, df_estruturas, model)\n",
        "  estruturas_recomendadas = ', '.join(estruturas_recomendadas)\n",
        "  resposta = \"Para o prompt: \" + prompt + \"\\n\" + \"SoluÃ§Ã£o identificada: \" + solucao_relacionada + \"\\n\" + \"Estruturas recomendadas: \" + estruturas_recomendadas + \"\\n\"\n",
        "  return resposta"
      ],
      "metadata": {
        "id": "L4_0aEjNWLI7"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GeraÃ§Ã£o de um Roteiro ðŸ““\n",
        "## Partes de um roteiro\n",
        "* Abertura\n",
        "* GeraÃ§Ã£o de idÃ©ias e ReflexÃ£o\n",
        "* Fechamento (aÃ§Ãµes)\n",
        "\n",
        "### Abertura: Quais as ELs mais indicadas? âš¡\n",
        "\n",
        "*Premissas:*\n",
        "* As com duraÃ§Ã£o < 15 min\n",
        "* Revelar, Disseminar\n",
        "\n",
        "ELs com duraÃ§Ã£o de atÃ© 15 min:\n",
        "* 1-2-4-All\n",
        "* Impromptu Networking\n",
        "* Wise Crowds\n",
        "\n",
        "### GeraÃ§Ã£o de idÃ©ias e ReflexÃ£o: Quais as ELs mais indicadas? âš¡\n",
        "\n",
        "*Premissas:*\n",
        "* Refletir, Analisar, Processamento, Revelar\n",
        "\n",
        "ELs com duraÃ§Ã£o de atÃ© 15 min:\n",
        "* Shift and Share\n",
        "\n",
        "\n",
        "### Fechamento: Quais as ELs mais indicadas? âš¡\n",
        "\n",
        "*Premissas:*\n",
        "* Revelar, disseminar, elaborar estratÃ©gias, planejar\n",
        "\n",
        "ELs recomendadas:\n",
        "* 15% Solutions\n",
        "* Min Specs\n",
        "* Conversation CafÃ©\n"
      ],
      "metadata": {
        "id": "6X7DNjMEc-o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GeraÃ§Ã£o de Roteiro\n",
        "#\n",
        "# DefiniÃ§Ã£o de dicionÃ¡rio de dados para seÃ§Ãµes do Roteiro\n",
        "\n",
        "# DefiniÃ§Ã£o das atividades para cada seÃ§Ã£o\n",
        "abertura_atividades = {\n",
        "    \"Fala 5 min\": {\n",
        "        \"descricao\": \"Cada pessoa compartilha algo que tem feito para se distrair.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 5\n",
        "    },\n",
        "    \"Check-in\": {\n",
        "        \"descricao\": \"Cada pessoa compartilha em uma palavra como estÃ¡ se sentindo.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 5\n",
        "    },\n",
        "    \"Desenho colaborativo\": {\n",
        "        \"descricao\": \"Em duplas, as pessoas se revezam completando um desenho.\",\n",
        "        \"formacao\": \"Duplas\",\n",
        "        \"duracao\": 10\n",
        "    }\n",
        "}\n",
        "\n",
        "reflexao_atividades = {\n",
        "    \"1-2-4-All\": {\n",
        "        \"descricao\": \"Brainstorming em etapas: individual, duplas, quartetos, e por fim, todos juntos.\",\n",
        "        \"formacao\": \"Variada\",\n",
        "        \"duracao\": 20\n",
        "    },\n",
        "    \"Mad Sad Glad\": {\n",
        "        \"descricao\": \"As pessoas escrevem o que as deixou felizes, tristes e irritadas durante a sprint.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 10\n",
        "    },\n",
        "    \"Linha do Tempo\": {\n",
        "        \"descricao\": \"Criar uma linha do tempo da sprint e marcar os principais eventos.\",\n",
        "        \"formacao\": \"Grupo\",\n",
        "        \"duracao\": 15\n",
        "    }\n",
        "}\n",
        "\n",
        "decisao_atividades = {\n",
        "    \"Dot Voting\": {\n",
        "        \"descricao\": \"Votar nos tÃ³picos mais importantes para serem discutidos.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 5\n",
        "    },\n",
        "    \"5 PorquÃªs\": {\n",
        "        \"descricao\": \"Investigar a causa raiz de um problema.\",\n",
        "        \"formacao\": \"Grupo\",\n",
        "        \"duracao\": 15\n",
        "    },\n",
        "    \"Plano de AÃ§Ã£o\": {\n",
        "        \"descricao\": \"Definir aÃ§Ãµes concretas para resolver os problemas priorizados.\",\n",
        "        \"formacao\": \"Grupo\",\n",
        "        \"duracao\": 20\n",
        "    }\n",
        "}\n",
        "\n",
        "fechamento_atividades = {\n",
        "    \"Check-out\": {\n",
        "        \"descricao\": \"Cada pessoa compartilha em uma palavra como se sente apÃ³s a retrospectiva.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 5\n",
        "    },\n",
        "    \"Um Agradecimento\": {\n",
        "        \"descricao\": \"Cada pessoa agradece a outra por algo especÃ­fico que contribuiu para a sprint.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 10\n",
        "    },\n",
        "    \"PrÃ³ximos Passos\": {\n",
        "        \"descricao\": \"Revisar o plano de aÃ§Ã£o e garantir que todos estejam cientes dos prÃ³ximos passos.\",\n",
        "        \"formacao\": \"Grupo\",\n",
        "        \"duracao\": 5\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "wzElo4J4uKZj"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o para encontrar ELs com base nos LabelEmbeddings\n",
        "def encontrar_estruturas_por_embeddings(embeddings, df, top_n=3):\n",
        "    # Calcula a similaridade entre os embeddings do prompt e os embeddings dos labels das ELs\n",
        "    similaridades = model.docvecs.similarity_query(embeddings, documents=df[\"label\"].tolist())\n",
        "\n",
        "    # Ordena as ELs por similaridade e seleciona as top_n\n",
        "    top_indices = sorted(range(len(similaridades)), key=lambda i: similaridades[i], reverse=True)[:top_n]\n",
        "    return df.iloc[top_indices]"
      ],
      "metadata": {
        "id": "H4OtH_an9GjY"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ã£o para gerar um roteiro\n",
        "def gerar_roteiro(prompt):\n",
        "    roteiro = {}\n",
        "\n",
        "    # Usar a funÃ§Ã£o busca para obter sugestÃµes de ELs\n",
        "    resultado_busca = busca(prompt)\n",
        "    estruturas_recomendadas_nomes = resultado_busca.split(\"Estruturas recomendadas: \")[1].strip().split(\", \")\n",
        "\n",
        "    # Encontrar as ELs no DataFrame usando os nomes recomendados\n",
        "    estruturas_recomendadas = df_estruturas[df_estruturas[\"nome\"].isin(estruturas_recomendadas_nomes)]\n",
        "\n",
        "    # ----> CorreÃ§Ã£o: Converter o DataFrame para dicionÃ¡rio\n",
        "    estruturas_dict = df_estruturas.set_index('nome').to_dict(orient='index')\n",
        "\n",
        "    # Selecionar as ELs adequadas para cada seÃ§Ã£o\n",
        "    reflexao_estrutura = None\n",
        "    decisao_estrutura = None\n",
        "\n",
        "    for estrutura_nome in estruturas_recomendadas_nomes:\n",
        "        if estrutura_nome in estruturas_dict:\n",
        "            estrutura_data = estruturas_dict[estrutura_nome]\n",
        "            if estrutura_data[\"label\"] in [\"Revelar\", \"Disseminar\", \"Compartilhar\"]:\n",
        "                reflexao_estrutura = estrutura_data\n",
        "            elif estrutura_data[\"label\"] in [\"Analisar\", \"Diagnosticar\", \"Processar\", \"Elaborar\", \"Planejar\"]:\n",
        "                decisao_estrutura = estrutura_data\n",
        "\n",
        "    # Adicionar as atividades ao roteiro\n",
        "    roteiro[\"Abertura\"] = random.choice(list(abertura_atividades.items()))\n",
        "\n",
        "    if reflexao_estrutura:\n",
        "        roteiro[\"ReflexÃ£o e Colhendo Dados\"] = (reflexao_estrutura[\"nome\"], {\n",
        "            \"descricao\": reflexao_estrutura[\"proposito\"],\n",
        "            \"formacao\": \"VariÃ¡vel\", # A formaÃ§Ã£o depende da EL especÃ­fica\n",
        "            \"duracao\": reflexao_estrutura[\"duracao\"]\n",
        "        })\n",
        "    else:\n",
        "        roteiro[\"ReflexÃ£o e Colhendo Dados\"] = random.choice(list(reflexao_atividades.items()))\n",
        "\n",
        "    if decisao_estrutura:\n",
        "        roteiro[\"Decidindo o que fazer\"] = (decisao_estrutura[\"nome\"], {\n",
        "            \"descricao\": decisao_estrutura[\"proposito\"],\n",
        "            \"formacao\": \"VariÃ¡vel\", # A formaÃ§Ã£o depende da EL especÃ­fica\n",
        "            \"duracao\": decisao_estrutura[\"duracao\"]\n",
        "        })\n",
        "    else:\n",
        "        roteiro[\"Decidindo o que fazer\"] = random.choice(list(decisao_atividades.items()))\n",
        "\n",
        "    roteiro[\"Fechamento\"] = random.choice(list(fechamento_atividades.items()))\n",
        "\n",
        "    return roteiro, resultado_busca"
      ],
      "metadata": {
        "id": "GoB6KzD89S2E"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_roteiro(roteiro):\n",
        "  print(\"# Retrospectiva (roteiro)\\n\")\n",
        "\n",
        "  for secao, (atividade, detalhes) in roteiro.items():\n",
        "      print(f\"## {secao}\")\n",
        "      print(f\"**DuraÃ§Ã£o:** {detalhes['duracao']} min\\n\")\n",
        "      print(f\"**FormaÃ§Ã£o:** {detalhes['formacao']}\\n\")\n",
        "      print(f\"**Atividade:** {atividade}\\n\")\n",
        "      print(f\"{detalhes['descricao']}\")\n",
        "      print()"
      ],
      "metadata": {
        "id": "YEJP3NRfvFF-"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparando e instanciando o modo generativo para respostas\n",
        "model_generative_config = {\n",
        "    \"temperature\": 2,\n",
        "    \"candidate_count\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 0,\n",
        "    \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "model_generative_safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "system_instruction = \"Seu nome Ã© Lisa. Uma assistente virtual, com habilidades de um Coach profissional e experiente facilitadora de reuniÃµes e atividades presenciais ou online com amplo conhecimento de aplicaÃ§Ã£o de Estruturas Libertadoras. Sempre pergunte ao usuÃ¡rio se ele deseja mais alguma informaÃ§Ã£o e o lembre que a palavra-chave para terminar a conversa Ã© 'fim'\"\n",
        "\n",
        "model_generative = genai.GenerativeModel(\"gemini-1.5-pro-latest\",\n",
        "                                         generation_config=model_generative_config,\n",
        "                                         system_instruction=system_instruction,\n",
        "                                         safety_settings=model_generative_safety_settings)"
      ],
      "metadata": {
        "id": "VJ3vYflKW9aB"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model_generative.start_chat(history=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\"Se apresente.\"]\n",
        "    },\n",
        "])"
      ],
      "metadata": {
        "id": "AaZHh2Z0bUom"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_chat_history(chat, role, message):\n",
        "  \"\"\"Adiciona uma nova entrada ao histÃ³rico da conversa.\n",
        "\n",
        "  Args:\n",
        "    chat: Objeto de chat do modelo generativo.\n",
        "    role: A funÃ§Ã£o na conversa (\"user\" ou \"assistant\").\n",
        "    message: A mensagem a ser adicionada.\n",
        "  \"\"\"\n",
        "  chat.history.append({\"role\": role, \"parts\": [message]})"
      ],
      "metadata": {
        "id": "Nh1tP1lhGfdB"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexto1 = \"Tenho um time recÃ©m criado que passou por muitas mudanÃ§as e seus membros precisam se reconectar uns com os outros\"\n",
        "contexto2 = \"Tenho um time experiente que apesar do bom clima interperssoal nÃ£o expÃµem seus problemas de maneira clara e construtiva\"\n",
        "contexto3 = \"Tenho um time experiente que precisa fazer melhorias no seu processo de trabalho para realizar entregas importantes num futuro breve\"\n",
        "prompt1 = \"A equipe estÃ¡ com dificuldade em se comunicar e tomar decisÃµes conjuntas.\"\n",
        "prompt2 = \"Um time que precisa formular novas idÃ©ias para construÃ§Ã£o do seu roadmap\"\n",
        "prompt3 = \"Um time estÃ¡ com dificuldade para encontrar o real motivo dos principais problemas a sua produtividade\"\n",
        "prompt4 = \"O time precisa melhorar as relaÃ§Ãµes entre seus integrantes\""
      ],
      "metadata": {
        "id": "CKPsaDACeqmb"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SaudaÃ§Ã£o inicial\n",
        "print(f\"OlÃ¡ eu sou Lisa!ðŸ‘‹\\n Uma assistente virtual especialista em criar roteiros para retrospectivas.\")\n",
        "print()\n",
        "print(\"A seguir, vocÃª pode descrever o contexto da sua equipe/time, e em seguida me fazer perguntas sobre detalhes da execuÃ§Ã£o de cada uma das atividades, ok?\")\n",
        "print(\"-\"*25)\n",
        "\n",
        "# Prompting (ROTEIRO)\n",
        "user_prompt = input(\"Descreva o contexto recente do time/equipe que deseja criar um roteiro: \")\n",
        "roteiro, resultado_busca = gerar_roteiro(user_prompt)\n",
        "print_roteiro(roteiro)\n",
        "\n",
        "# Atualiza o historico do modelo generativo para ele ter contexto para iteraÃ§Ãµes futuras\n",
        "update_chat_history(chat, \"user\", f\"Solicito a criaÃ§Ã£o de um roteiro de retrospectiva para {user_prompt}\")\n",
        "update_chat_history(chat, \"model\", f\"{roteiro}\")\n",
        "\n",
        "# Inicio do modo generativo\n",
        "print(\"-\"*25)\n",
        "print(\"Gostou do seu roteiro? Se quiser mais detalhes sobre as atividades Ã© sÃ³ me perguntar, \\nou se desejar terminar a conversa, envie a mensagem 'fim'.\")\n",
        "print()\n",
        "\n",
        "# Loop do modo generativo\n",
        "while True:\n",
        "    # Prompting (GENERATIVO)\n",
        "    user_prompt = input(\">>> \")\n",
        "\n",
        "    # Verifica se o usuÃ¡rio deseja terminar a conversa\n",
        "    if user_prompt.strip().lower() == \"fim\":\n",
        "        print(\"AtÃ© mais! ðŸ‘‹\")\n",
        "        break\n",
        "\n",
        "    # Envia a pergunta ao modelo generativo\n",
        "    resposta = chat.send_message(user_prompt)\n",
        "\n",
        "    # Imprime a resposta do modelo\n",
        "    print(resposta.text)\n"
      ],
      "metadata": {
        "id": "vHJKNsEWYN2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}