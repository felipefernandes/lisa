{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaCtzDSsV6dnl4AjAuSQ2W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipefernandes/lisa/blob/main/LiSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "wSN_aaruIpsk"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -q -U pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import hashlib\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata, drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import random"
      ],
      "metadata": {
        "id": "WJ8xaTlGJFfo"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do GenerativeAI\n",
        "GOOGLE_API_KEY = userdata.get('GEMINIKEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "jRlmthAkKgYN"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listando modelos disponíveis\n",
        "for m in genai.list_models():\n",
        "  if 'embedContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "kRHd9XA4KWOu",
        "outputId": "22f46eaa-6d39-4b73-d7df-edc6b5bd7c8c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-001\n",
            "models/text-embedding-004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação de Dicionários\n",
        "\n",
        "estruturas = [\n",
        "    {\"nome\": \"Impromptu Networking\", \"duracao\": \"5-20 min\", \"proposito\": \"Compartilhe rapidamente os desafios e as expectativas, crie novas conexões\", \"label\": \"Disseminar\"},\n",
        "    {\"nome\": \"9 Whys\", \"duracao\": \"5-20 min\", \"proposito\": \"Torne claro o propósito do trabalho juntos\", \"label\": \"Analisar\"},\n",
        "    {\"nome\": \"What, So What, Now What\", \"duracao\": \"15-45 min\", \"proposito\": \"Analisar juntos o progresso até então e decidir quais ajustes são necessários\", \"label\": \"Analisar\"},\n",
        "    {\"nome\": \"TRIZ\", \"duracao\": \"30-45 min\", \"proposito\": \"Pare atividades e comportamentos contraproducentes para abrir espaço para a inovação\", \"label\": \"Revelar\"},\n",
        "    {\"nome\": \"Appreciative Interviews\", \"duracao\": \"30-60 min\", \"proposito\": \"Descobrindo e aproveitando as causas-raiz do sucesso\", \"label\": \"Revelar, Disseminar\"},\n",
        "    {\"nome\": \"1-2-4-All\", \"duracao\": \"10-12 min\", \"proposito\": \"Engage todos simultaneamente na geração de perguntas, ideias e sugestões.\", \"label\": \"Revelar\"},\n",
        "    {\"nome\": \"User Experience Fishbowl\", \"duracao\": \"25-70 min\", \"proposito\": \"Compartilhe com uma comunidade maior a capacidade obtida a partir da experiência\", \"label\": \"Disseminar\"},\n",
        "    {\"nome\": \"15% Solutions\", \"duracao\": \"15-20 min\", \"proposito\": \"Descubra e concentre-se no que cada pessoa tem a liberdade e os recursos para fazer agora\", \"label\": \"Revelar\"},\n",
        "    {\"nome\": \"25-to-10 Crowdsourcing\", \"duracao\": \"20-30 min\", \"proposito\": \"Gerar e analisar rapidamente as ideias factíveis mais poderosas de um grupo\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Troika Consulting\", \"duracao\": \"15-30 min\", \"proposito\": \"Obtenha ajuda prática e criativa dos colegas imediatamente\", \"label\": \"Ajuda, Revelar\"},\n",
        "    { \"nome\": \"Conversation Café\", \"duracao\": \"35-60 min\", \"proposito\": \"Engage todos na compreensão de grandes desafios\", \"label\": \"Disseminar\"},\n",
        "    { \"nome\": \"Min Specs\", \"duracao\": \"20-50 min\", \"proposito\": \"Especifique apenas os absolutos “Devemos” e “Não Devemos” para alcançar um propósito\", \"label\": \"Estratégia\"},\n",
        "    { \"nome\": \"Wise Crowds\", \"duracao\": \"10-60 min. per person\", \"proposito\": \"Acesse a sabedoria do grupo inteiro em ciclos rápidos\", \"label\": \"Ajuda, Revelar\"},\n",
        "    { \"nome\": \"Wicked Questions\", \"duracao\": \"20 min\", \"proposito\": \"Articule os desafios paradoxais que um grupo deve enfrentar para ter sucesso\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Drawing Together\", \"duracao\": \"30-40 min\", \"proposito\": \"Revele ideias e caminhos para avançar através da expressão não-verbal\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Improv Prototyping\", \"duracao\": \"15-20 min. per round\", \"proposito\": \"Desenvolva soluções eficazes para desafios crônicos, enquanto se diverte seriamente\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Agreement-Certainty Matrix\", \"duracao\": \"30-45 min\", \"proposito\": \"Classifique os desafios nos domínios simples, complicado, complexo e caótico\", \"label\": \"Análise\"},\n",
        "    { \"nome\": \"Shift & Share\", \"duracao\": \"35-90 min\", \"proposito\": \"Dissemine boas ideias e faça conexões informais com inovadores\", \"label\": \"Disseminar\"},\n",
        "    { \"nome\": \"Heard, Seen, Respected\", \"duracao\": \"25 min\", \"proposito\": \"Pratique a escuta profunda e empatia com colegas\", \"label\": \"Ajuda\"},\n",
        "    { \"nome\": \"Social Network Webbing\", \"duracao\": \"45-60 min\", \"proposito\": \"Mapeie conexões informais e decida como fortalecer a rede para alcançar um propósito\", \"label\": \"Ajuda, Disseminar\"},\n",
        "    { \"nome\": \"Design Storyboards\", \"duracao\": \"25-70 min\", \"proposito\": \"Defina os elementos passo-a-passo para conduzir reuniões a finais produtivos\", \"label\": \"Planejar\"},\n",
        "    { \"nome\": \"Open Space\", \"duracao\": \"90 min. to 3 days\", \"proposito\": \"Libere a ação e liderança inerentes a grupos de qualquer tamanho\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Discovery & Action Dialogue\", \"duracao\": \"25-70 min\", \"proposito\": \"Descubra, invente e desencadeie soluções locais para problemas crônicos\", \"label\": \"Revelar\"},\n",
        "    { \"nome\": \"Integrated Autonomy\", \"duracao\": \"60-80 min\", \"proposito\": \"Mude de soluções 'ou-um-ou-outro' para robustas soluções 'ambos-e'\", \"label\": \"Estratégia\"},\n",
        "    { \"nome\": \"Generative Relationships\", \"duracao\": \"25 min\", \"proposito\": \"Revele padrões de relacionamento que criam surpreendente valor ou disfunções\", \"label\": \"Análise\"},\n",
        "    { \"nome\": \"Critical Uncertainties\", \"duracao\": \"60-100 min\", \"proposito\": \"Desenvolva estratégias para operar em uma variedade de futuros plausíveis porém imprevisíveis\", \"label\": \"Estratégia\"},\n",
        "    { \"nome\": \"Purpose-to-Practice\", \"duracao\": \"25-120 min\", \"proposito\": \"Desenhe os cinco elementos essenciais para uma iniciativa resiliente e duradoura\", \"label\": \"Planejar\"},\n",
        "    { \"nome\": \"Ecocycle Planning\", \"duracao\": \"60-95 min\", \"proposito\": \"Analise o portfólio completo de atividades e relacionamentos para identificar obstáculos e oportunidades para o progresso\", \"label\": \"Análise, Estratégia\"},\n",
        "    { \"nome\": \"Panarchy\", \"duracao\": \"1-2 hr\", \"proposito\": \"Entenda como sistemas interconectados interagem, evoluem, disseminam inovação e transformam\", \"label\": \"Estratégia\"},\n",
        "    { \"nome\": \"What I Need From You\", \"duracao\": \"45-70 min\", \"proposito\": \"Faça emergir as necessidades essenciais entre áreas e aceite ou rejeite pedidos de suporte\", \"label\": \"Ajuda\"},\n",
        "    { \"nome\": \"Celebrity Interview\", \"duracao\": \"25-60 min\", \"proposito\": \"Reconectar a experiência de líderes e especialistas com pessoas mais próximas do desafio em mãos\", \"label\": \"Disseminar\"},\n",
        "    { \"nome\": \"Helping Heuristics\", \"duracao\": \"15 min\", \"proposito\": \"Pratique métodos progressivos para ajudar os outros, receber ajuda e pedir ajuda\", \"label\": \"Ajuda\"},\n",
        "    { \"nome\": \"Simple Ethnography\", \"duracao\": \"1-6 hr\", \"proposito\": \"Observe e registre os comportamentos reais dos usuários em campo\", \"label\": \"Análise, Revelar\"}\n",
        "]\n",
        "\n",
        "solucoes = [\n",
        "    {\"solucao\": \"Revelar, gerar aprimorar idéias ou soluções\"},\n",
        "    {\"solucao\": \"Compartilhar ou disseminar idéias, conhecimentos ou experiências\"},\n",
        "    {\"solucao\": \"Analisar, diagnosticar ou processar\"},\n",
        "    {\"solucao\": \"Pedir ou oferecer ajuda\"},\n",
        "    {\"solucao\": \"Elaborar estratégias\"},\n",
        "    {\"solucao\": \"Planejar\"}\n",
        "]"
      ],
      "metadata": {
        "id": "LhOuJwEfLNgv"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrames\n",
        "\n",
        "* Pense em um DataFrame como uma tabela organizada, com linhas e colunas.\n",
        "* Cada linha representa um roteiro de retrospectiva e cada coluna contém informações específicas sobre esse roteiro, como nome, descrição, atividades, etc.\n",
        "* Essa organização facilita o armazenamento e a busca de informações."
      ],
      "metadata": {
        "id": "kune8xgMRCk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_estruturas = pd.DataFrame(estruturas)\n",
        "df_estruturas.columns = ['nome', 'duracao', 'proposito', 'label']\n",
        "\n",
        "df_solucoes = pd.DataFrame(solucoes)\n",
        "df_solucoes.columns = ['solucao']"
      ],
      "metadata": {
        "id": "a6NXpp_WQTS_"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings\n",
        "\n",
        "* Embeddings são como **representações matemáticas de textos**, transformando palavras e frases em sequências de números.\n",
        "* Essa representação numérica captura o **significado semântico** do texto.\n",
        "* Palavras com significados semelhantes terão embeddings parecidos, permitindo comparar a similaridade entre textos de forma eficiente.\n",
        "\n",
        "### Juntos, DataFrames e Embeddings permitem:\n",
        "1. **Armazenar os roteiros de forma estruturada** dentro do DataFrame.\n",
        "2. **Converter o contexto fornecido pelo usuário e as descrições dos roteiros em embeddings.**\n",
        "3. **Comparar os embeddings usando cálculos matemáticos**, encontrando os roteiros mais relevantes para o contexto descrito.\n",
        "\n",
        "##### **Em resumo:** DataFrames organizam os dados, enquanto embeddings traduzem os textos em uma linguagem que o computador entende, permitindo encontrar o roteiro perfeito para sua necessidade!"
      ],
      "metadata": {
        "id": "TYgikh5DRLx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando o modelo\n",
        "model = \"models/embedding-001\""
      ],
      "metadata": {
        "id": "5HJkgKzsSOex"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para adicionar colunas de Embeds no DF Estruturas, conteudo principal titulo e descricao\n",
        "def addEmbeddings(nome, proposito):\n",
        "  return genai.embed_content(model=model, content=proposito, title=nome, task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "\n",
        "# Adicionando Embeddings no DataFrame\n",
        "df_estruturas[\"Embeddings\"] = df_estruturas.apply(lambda row: addEmbeddings(row[\"nome\"], row[\"proposito\"]), axis=1)"
      ],
      "metadata": {
        "id": "KSpVTvukSbre"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para adicionar uma coluna de Embeddings para Label\n",
        "def addLabelEmbeddings(label):\n",
        "  return genai.embed_content(model=model, content=label, task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "\n",
        "# Adicionando nova coluna de Embeddings para Label\n",
        "df_estruturas[\"LabelEmbeddings\"] = df_estruturas.apply(lambda row: addLabelEmbeddings(row[\"label\"]), axis=1)"
      ],
      "metadata": {
        "id": "_m0yv8OUQimJ"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para adicionar colunas embeddings no DF de Solucoes\n",
        "def addSolucaoEmbeddings(solucao):\n",
        "  return genai.embed_content(model=model, content=solucao, task_type=\"RETRIEVAL_DOCUMENT\")[\"embedding\"]\n",
        "\n",
        "df_solucoes[\"Embeddings\"] = df_solucoes.apply(lambda row: addSolucaoEmbeddings(row[\"solucao\"]), axis=1)"
      ],
      "metadata": {
        "id": "JBduiZnOR8CA"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Produtos Escalares & Embeddings\n",
        "\n",
        "A função `buscar_solucao_consulta` utiliza uma técnica poderosa para encontrar a solução mais adequada para sua consulta: o produto escalar entre embeddings.\n",
        "### Mas como isso funciona?\n",
        "1. **Embeddings**: Cada texto, tanto a sua consulta quanto as soluções pré-definidas, é convertido em um embedding, uma representação matemática que captura seu significado. Imagine que cada palavra se transforma em um ponto em um espaço multidimensional, e frases com significados semelhantes ficam próximas nesse espaço.\n",
        "2. **Produto Escalar**: O produto escalar é uma operação matemática que mede a similaridade entre dois vetores (no nosso caso, os embeddings). Ele leva em consideração a **direção** e a **magnitude** dos vetores.\n",
        "  * Um produto escalar alto indica vetores apontando na mesma direção, significando alta similaridade entre os textos.\n",
        "  * Um produto escalar baixo indica vetores apontando em direções diferentes, significando baixa similaridade.\n",
        "3. **Encontrando a Melhor Solução**: A função calcula o produto escalar entre o embedding da sua consulta e os embeddings de cada solução na base de dados. O índice da solução com o **maior produto escalar** indica a solução mais similar à sua consulta, sendo a mais adequada para o contexto descrito.\n",
        "\n",
        "**Em resumo:** o produto escalar atua como um \"termômetro\" de similaridade, permitindo encontrar a solução mais próxima à sua necessidade, com base no significado semântico dos textos!\n",
        "\n",
        "#### Analogia:\n",
        "Imagine que as palavras são como cidades em um mapa. Cidades próximas têm mais similaridade. O produto escalar seria como medir a distância entre a sua \"cidade-consulta\" e as \"cidades-soluções\". A cidade-solução mais próxima (menor distância, maior produto escalar) é a mais relevante para sua consulta."
      ],
      "metadata": {
        "id": "080qCFNDSYS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para verificar consulta tem relação com alguma dos itens do DF solução\n",
        "def buscar_solucao_consulta(consulta, base, model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model, content=consulta, task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "  produtos_escalares = np.dot(np.stack(base['Embeddings']), embedding_da_consulta)\n",
        "  indice = np.argmax(produtos_escalares)\n",
        "  return base.iloc[indice]['solucao']"
      ],
      "metadata": {
        "id": "W_WPt6SdUG00"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Limite de Relevancia\n",
        "\n",
        "* O `limite_relevancia` atua como um filtro, determinando quais resultados são considerados \"relevantes\" com base no produto escalar entre o embedding da consulta e os embeddings da sua base de dados (`df_estruturas`).\n",
        "* Um produto escalar próximo de 1 indica alta similaridade entre os vetores, enquanto um valor próximo de 0 indica baixa similaridade.\n",
        "\n",
        "## Ajustando o Limite de Relevancia:\n",
        "* **Aumentar o limite (mais perto de 1)**:\n",
        "  * Somente resultados **muito similares** à consulta serão considerados relevantes.\n",
        "  * Útil se você deseja resultados **precisos** e tem certeza de que a consulta corresponde bem aos dados na sua base.\n",
        "  * Risco: Pode resultar em **nenhum resultado** se a consulta for muito específica ou não houver correspondência exata na base.\n",
        "* **Diminuir o limite (mais perto de 0)**:\n",
        "  * Resultados **menos similares** à consulta também serão considerados relevantes.\n",
        "  * Útil para **explorar** a base de dados ou quando a consulta é mais vaga.\n",
        "  * Risco: Pode retornar **resultados irrelevantes** ou que não correspondem exatamente à intenção da consulta."
      ],
      "metadata": {
        "id": "GhVO05FrPZ3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para gerar e buscar e consultar\n",
        "def gerar_e_buscar_consulta(consulta, base, model):\n",
        "  embedding_da_consulta = genai.embed_content(model=model, content=consulta, task_type=\"RETRIEVAL_QUERY\")[\"embedding\"]\n",
        "\n",
        "  produtos_escalares = np.dot(np.stack(df_estruturas['LabelEmbeddings']), embedding_da_consulta)\n",
        "\n",
        "  limite_relevancia = 0.6 # Definindo o limite da relevancia\n",
        "  indices_relevantes = np.where(produtos_escalares >= limite_relevancia)[0]\n",
        "\n",
        "  resultados_relevantes = []\n",
        "  for indice in indices_relevantes:\n",
        "    resultados_relevantes.append(df_estruturas.iloc[indice]['nome'])\n",
        "\n",
        "  top3_resultados_relevantes = []\n",
        "  top3 = 0\n",
        "  if resultados_relevantes:\n",
        "    while top3 < 3 and top3 < len(resultados_relevantes):  # Verifica se há elementos suficientes\n",
        "      # Exibe a primeira posicao de resultados_relevante\n",
        "      top3_resultados_relevantes.append(resultados_relevantes[top3])\n",
        "      top3 += 1\n",
        "    return top3_resultados_relevantes # Exibe uma lista de resultados relevantes\n",
        "  else:\n",
        "    indice = np.argmax(produtos_escalares)\n",
        "    return df_estruturas.iloc[indice]['nome'] # garante que ao menos 1 resultado seja exibido"
      ],
      "metadata": {
        "id": "Clyg4_pBU4jX"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Busca e retorna solucoes e ELs recomendadas de acordo com um Prompt\n",
        "def busca (prompt):\n",
        "  solucao_relacionada = buscar_solucao_consulta(prompt, df_solucoes, model)\n",
        "  estruturas_recomendadas = gerar_e_buscar_consulta(prompt, df_estruturas, model)\n",
        "  estruturas_recomendadas = ', '.join(estruturas_recomendadas)\n",
        "  resposta = \"Para o prompt: \" + prompt + \"\\n\" + \"Solução identificada: \" + solucao_relacionada + \"\\n\" + \"Estruturas recomendadas: \" + estruturas_recomendadas + \"\\n\"\n",
        "  return resposta"
      ],
      "metadata": {
        "id": "L4_0aEjNWLI7"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geração de um Roteiro 📓\n",
        "## Partes de um roteiro\n",
        "* Abertura\n",
        "* Geração de idéias e Reflexão\n",
        "* Fechamento (ações)\n",
        "\n",
        "### Abertura: Quais as ELs mais indicadas? ⚡\n",
        "\n",
        "*Premissas:*\n",
        "* As com duração < 15 min\n",
        "* Revelar, Disseminar\n",
        "\n",
        "ELs com duração de até 15 min:\n",
        "* 1-2-4-All\n",
        "* Impromptu Networking\n",
        "* Wise Crowds\n",
        "\n",
        "### Geração de idéias e Reflexão: Quais as ELs mais indicadas? ⚡\n",
        "\n",
        "*Premissas:*\n",
        "* Refletir, Analisar, Processamento, Revelar\n",
        "\n",
        "ELs com duração de até 15 min:\n",
        "* Shift and Share\n",
        "\n",
        "\n",
        "### Fechamento: Quais as ELs mais indicadas? ⚡\n",
        "\n",
        "*Premissas:*\n",
        "* Revelar, disseminar, elaborar estratégias, planejar\n",
        "\n",
        "ELs recomendadas:\n",
        "* 15% Solutions\n",
        "* Min Specs\n",
        "* Conversation Café\n"
      ],
      "metadata": {
        "id": "6X7DNjMEc-o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Geração de Roteiro\n",
        "#\n",
        "# Definição de dicionário de dados para seções do Roteiro\n",
        "\n",
        "# Definição das atividades para cada seção\n",
        "abertura_atividades = {\n",
        "    \"Fala 5 min\": {\n",
        "        \"descricao\": \"Cada pessoa compartilha algo que tem feito para se distrair.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 5\n",
        "    },\n",
        "    \"Check-in\": {\n",
        "        \"descricao\": \"Cada pessoa compartilha em uma palavra como está se sentindo.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 5\n",
        "    },\n",
        "    \"Desenho colaborativo\": {\n",
        "        \"descricao\": \"Em duplas, as pessoas se revezam completando um desenho.\",\n",
        "        \"formacao\": \"Duplas\",\n",
        "        \"duracao\": 10\n",
        "    }\n",
        "}\n",
        "\n",
        "reflexao_atividades = {\n",
        "    \"1-2-4-All\": {\n",
        "        \"descricao\": \"Brainstorming em etapas: individual, duplas, quartetos, e por fim, todos juntos.\",\n",
        "        \"formacao\": \"Variada\",\n",
        "        \"duracao\": 20\n",
        "    },\n",
        "    \"Mad Sad Glad\": {\n",
        "        \"descricao\": \"As pessoas escrevem o que as deixou felizes, tristes e irritadas durante a sprint.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 10\n",
        "    },\n",
        "    \"Linha do Tempo\": {\n",
        "        \"descricao\": \"Criar uma linha do tempo da sprint e marcar os principais eventos.\",\n",
        "        \"formacao\": \"Grupo\",\n",
        "        \"duracao\": 15\n",
        "    }\n",
        "}\n",
        "\n",
        "decisao_atividades = {\n",
        "    \"Dot Voting\": {\n",
        "        \"descricao\": \"Votar nos tópicos mais importantes para serem discutidos.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 5\n",
        "    },\n",
        "    \"5 Porquês\": {\n",
        "        \"descricao\": \"Investigar a causa raiz de um problema.\",\n",
        "        \"formacao\": \"Grupo\",\n",
        "        \"duracao\": 15\n",
        "    },\n",
        "    \"Plano de Ação\": {\n",
        "        \"descricao\": \"Definir ações concretas para resolver os problemas priorizados.\",\n",
        "        \"formacao\": \"Grupo\",\n",
        "        \"duracao\": 20\n",
        "    }\n",
        "}\n",
        "\n",
        "fechamento_atividades = {\n",
        "    \"Check-out\": {\n",
        "        \"descricao\": \"Cada pessoa compartilha em uma palavra como se sente após a retrospectiva.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 5\n",
        "    },\n",
        "    \"Um Agradecimento\": {\n",
        "        \"descricao\": \"Cada pessoa agradece a outra por algo específico que contribuiu para a sprint.\",\n",
        "        \"formacao\": \"Individual\",\n",
        "        \"duracao\": 10\n",
        "    },\n",
        "    \"Próximos Passos\": {\n",
        "        \"descricao\": \"Revisar o plano de ação e garantir que todos estejam cientes dos próximos passos.\",\n",
        "        \"formacao\": \"Grupo\",\n",
        "        \"duracao\": 5\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "wzElo4J4uKZj"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para encontrar ELs com base nos LabelEmbeddings\n",
        "def encontrar_estruturas_por_embeddings(embeddings, df, top_n=3):\n",
        "    # Calcula a similaridade entre os embeddings do prompt e os embeddings dos labels das ELs\n",
        "    similaridades = model.docvecs.similarity_query(embeddings, documents=df[\"label\"].tolist())\n",
        "\n",
        "    # Ordena as ELs por similaridade e seleciona as top_n\n",
        "    top_indices = sorted(range(len(similaridades)), key=lambda i: similaridades[i], reverse=True)[:top_n]\n",
        "    return df.iloc[top_indices]"
      ],
      "metadata": {
        "id": "H4OtH_an9GjY"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para gerar um roteiro\n",
        "def gerar_roteiro(prompt):\n",
        "    roteiro = {}\n",
        "\n",
        "    # Usar a função busca para obter sugestões de ELs\n",
        "    resultado_busca = busca(prompt)\n",
        "    estruturas_recomendadas_nomes = resultado_busca.split(\"Estruturas recomendadas: \")[1].strip().split(\", \")\n",
        "\n",
        "    # Encontrar as ELs no DataFrame usando os nomes recomendados\n",
        "    estruturas_recomendadas = df_estruturas[df_estruturas[\"nome\"].isin(estruturas_recomendadas_nomes)]\n",
        "\n",
        "    # ----> Correção: Converter o DataFrame para dicionário\n",
        "    estruturas_dict = df_estruturas.set_index('nome').to_dict(orient='index')\n",
        "\n",
        "    # Selecionar as ELs adequadas para cada seção\n",
        "    reflexao_estrutura = None\n",
        "    decisao_estrutura = None\n",
        "\n",
        "    for estrutura_nome in estruturas_recomendadas_nomes:\n",
        "        if estrutura_nome in estruturas_dict:\n",
        "            estrutura_data = estruturas_dict[estrutura_nome]\n",
        "            if estrutura_data[\"label\"] in [\"Revelar\", \"Disseminar\", \"Compartilhar\"]:\n",
        "                reflexao_estrutura = estrutura_data\n",
        "            elif estrutura_data[\"label\"] in [\"Analisar\", \"Diagnosticar\", \"Processar\", \"Elaborar\", \"Planejar\"]:\n",
        "                decisao_estrutura = estrutura_data\n",
        "\n",
        "    # Adicionar as atividades ao roteiro\n",
        "    roteiro[\"Abertura\"] = random.choice(list(abertura_atividades.items()))\n",
        "\n",
        "    if reflexao_estrutura:\n",
        "        roteiro[\"Reflexão e Colhendo Dados\"] = (reflexao_estrutura[\"nome\"], {\n",
        "            \"descricao\": reflexao_estrutura[\"proposito\"],\n",
        "            \"formacao\": \"Variável\", # A formação depende da EL específica\n",
        "            \"duracao\": reflexao_estrutura[\"duracao\"]\n",
        "        })\n",
        "    else:\n",
        "        roteiro[\"Reflexão e Colhendo Dados\"] = random.choice(list(reflexao_atividades.items()))\n",
        "\n",
        "    if decisao_estrutura:\n",
        "        roteiro[\"Decidindo o que fazer\"] = (decisao_estrutura[\"nome\"], {\n",
        "            \"descricao\": decisao_estrutura[\"proposito\"],\n",
        "            \"formacao\": \"Variável\", # A formação depende da EL específica\n",
        "            \"duracao\": decisao_estrutura[\"duracao\"]\n",
        "        })\n",
        "    else:\n",
        "        roteiro[\"Decidindo o que fazer\"] = random.choice(list(decisao_atividades.items()))\n",
        "\n",
        "    roteiro[\"Fechamento\"] = random.choice(list(fechamento_atividades.items()))\n",
        "\n",
        "    return roteiro, resultado_busca"
      ],
      "metadata": {
        "id": "GoB6KzD89S2E"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_roteiro(roteiro):\n",
        "  print(\"# Retrospectiva (roteiro)\\n\")\n",
        "\n",
        "  for secao, (atividade, detalhes) in roteiro.items():\n",
        "      print(f\"## {secao}\")\n",
        "      print(f\"**Duração:** {detalhes['duracao']} min\\n\")\n",
        "      print(f\"**Formação:** {detalhes['formacao']}\\n\")\n",
        "      print(f\"**Atividade:** {atividade}\\n\")\n",
        "      print(f\"{detalhes['descricao']}\")\n",
        "      print()"
      ],
      "metadata": {
        "id": "YEJP3NRfvFF-"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparando e instanciando o modo generativo para respostas\n",
        "model_generative_config = {\n",
        "    \"temperature\": 2,\n",
        "    \"candidate_count\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 0,\n",
        "    \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "model_generative_safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "system_instruction = \"Seu nome é Lisa. Uma assistente virtual, com habilidades de um Coach profissional e experiente facilitadora de reuniões e atividades presenciais ou online com amplo conhecimento de aplicação de Estruturas Libertadoras. Sempre pergunte ao usuário se ele deseja mais alguma informação e o lembre que a palavra-chave para terminar a conversa é 'fim'\"\n",
        "\n",
        "model_generative = genai.GenerativeModel(\"gemini-1.5-pro-latest\",\n",
        "                                         generation_config=model_generative_config,\n",
        "                                         system_instruction=system_instruction,\n",
        "                                         safety_settings=model_generative_safety_settings)"
      ],
      "metadata": {
        "id": "VJ3vYflKW9aB"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model_generative.start_chat(history=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\"Se apresente.\"]\n",
        "    },\n",
        "])"
      ],
      "metadata": {
        "id": "AaZHh2Z0bUom"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_chat_history(chat, role, message):\n",
        "  \"\"\"Adiciona uma nova entrada ao histórico da conversa.\n",
        "\n",
        "  Args:\n",
        "    chat: Objeto de chat do modelo generativo.\n",
        "    role: A função na conversa (\"user\" ou \"assistant\").\n",
        "    message: A mensagem a ser adicionada.\n",
        "  \"\"\"\n",
        "  chat.history.append({\"role\": role, \"parts\": [message]})"
      ],
      "metadata": {
        "id": "Nh1tP1lhGfdB"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexto1 = \"Tenho um time recém criado que passou por muitas mudanças e seus membros precisam se reconectar uns com os outros\"\n",
        "contexto2 = \"Tenho um time experiente que apesar do bom clima interperssoal não expõem seus problemas de maneira clara e construtiva\"\n",
        "contexto3 = \"Tenho um time experiente que precisa fazer melhorias no seu processo de trabalho para realizar entregas importantes num futuro breve\"\n",
        "prompt1 = \"A equipe está com dificuldade em se comunicar e tomar decisões conjuntas.\"\n",
        "prompt2 = \"Um time que precisa formular novas idéias para construção do seu roadmap\"\n",
        "prompt3 = \"Um time está com dificuldade para encontrar o real motivo dos principais problemas a sua produtividade\"\n",
        "prompt4 = \"O time precisa melhorar as relações entre seus integrantes\""
      ],
      "metadata": {
        "id": "CKPsaDACeqmb"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saudação inicial\n",
        "print(f\"Olá eu sou Lisa!👋\\n Uma assistente virtual especialista em criar roteiros para retrospectivas.\")\n",
        "print()\n",
        "print(\"A seguir, você pode descrever o contexto da sua equipe/time, e em seguida me fazer perguntas sobre detalhes da execução de cada uma das atividades, ok?\")\n",
        "print(\"-\"*25)\n",
        "\n",
        "# Prompting (ROTEIRO)\n",
        "user_prompt = input(\"Descreva o contexto recente do time/equipe que deseja criar um roteiro: \")\n",
        "roteiro, resultado_busca = gerar_roteiro(user_prompt)\n",
        "print_roteiro(roteiro)\n",
        "\n",
        "# Atualiza o historico do modelo generativo para ele ter contexto para iterações futuras\n",
        "update_chat_history(chat, \"user\", f\"Solicito a criação de um roteiro de retrospectiva para {user_prompt}\")\n",
        "update_chat_history(chat, \"model\", f\"{roteiro}\")\n",
        "\n",
        "# Inicio do modo generativo\n",
        "print(\"-\"*25)\n",
        "print(\"Gostou do seu roteiro? Se quiser mais detalhes sobre as atividades é só me perguntar, \\nou se desejar terminar a conversa, envie a mensagem 'fim'.\")\n",
        "print()\n",
        "\n",
        "# Loop do modo generativo\n",
        "while True:\n",
        "    # Prompting (GENERATIVO)\n",
        "    user_prompt = input(\">>> \")\n",
        "\n",
        "    # Verifica se o usuário deseja terminar a conversa\n",
        "    if user_prompt.strip().lower() == \"fim\":\n",
        "        print(\"Até mais! 👋\")\n",
        "        break\n",
        "\n",
        "    # Envia a pergunta ao modelo generativo\n",
        "    resposta = chat.send_message(user_prompt)\n",
        "\n",
        "    # Imprime a resposta do modelo\n",
        "    print(resposta.text)\n"
      ],
      "metadata": {
        "id": "vHJKNsEWYN2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}